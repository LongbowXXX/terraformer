# Copilot Custom Prompting Techniques

This document summarizes effective techniques for creating custom prompts for GitHub Copilot in VS Code.

## Task Management with `#todos`

### Problem

When a custom prompt requires performing multiple complex operations (e.g., analyzing context, generating multiple files, validating links), Copilot may occasionally skip steps or lose track of progress, leading to incomplete results.

### Solution

Enforce structured execution by explicitly registering tasks using the `#todos` tool at the beginning of the prompt and requiring a final verification step.

### Implementation Steps

1.  **Task Initialization**:
    At the very beginning of the prompt (after the role definition), instruct Copilot to immediately use the `#todos` tool to register all high-level tasks.

2.  **Final Verification**:
    Add a "Final Check" section at the end of the prompt that requires Copilot to confirm all registered todos are completed.

### Example Template

```markdown
# Role: [Role Name]

...

## ðŸ“‹ Task Initialization

**IMMEDIATELY** use the `#todos` tool to register the following tasks to track your progress:

1.  **Step 1**: [Description of step 1]
2.  **Step 2**: [Description of step 2]
3.  **Validation**: Perform checks.
4.  **Final Check**: Review the "Final Check" section.

... [Rest of the prompt] ...

## âœ… Final Check

**Before finishing, confirm:**

- [ ] All todos are marked as completed.
- [ ] All requirements are met.
```

### Benefits

- **Visibility**: Users can see the planned tasks in the "Todos" view.
- **Completeness**: Reduces the risk of missing steps in complex workflows.
- **Self-Correction**: Encourages the model to review its own work against the checklist.

## Knowledge Retrieval for Latest Specifications

### Problem

Copilot's training data has a cutoff, so it may not know about the latest features, file structures, or tools available in VS Code Copilot (e.g., new prompt file formats, new chat tools).

### Solution

Explicitly instruct Copilot to fetch the latest documentation from official URLs at the beginning of the prompt before performing any generation tasks.

### Implementation Steps

1.  **Identify Critical URLs**:
    Determine which documentation pages contain the specifications relevant to your prompt (e.g., prompt files, custom agents, tools).

2.  **Add Prerequisite Section**:
    Add a section (e.g., "PREREQUISITE: Knowledge Retrieval") that forces Copilot to read these URLs.

### Example Template

```markdown
## ðŸš¨ PREREQUISITE: Knowledge Retrieval

**Before generating or updating, you MUST:**

1.  **Fetch Latest Docs**:
    - `https://code.visualstudio.com/docs/copilot/customization/prompt-files` (for prompt file structure).
    - `https://code.visualstudio.com/docs/copilot/reference/copilot-vscode-features#_chat-tools` (for available tools).
    - `https://code.visualstudio.com/docs/copilot/customization/custom-agents` (for custom agent structure).
```

### Benefits

- **Accuracy**: Ensures generated files comply with the latest schemas and standards.
- **Capability**: Enables the use of the newest tools and features that the model might not inherently know.

## Transparency & Hallucination Management

### Problem

Users may unknowingly treat AI-generated content as "Gold Standard," leading to critical errors if hallucinations go unnoticed. Conversely, users may spend excessive time correcting minor, non-critical AI mistakes, negating the efficiency gains of using AI.

### Solution

Enforce a "Transparency" policy by requiring AI agents to embed a specific generation tag at the top of all created documents. This explicitly labels the content as an AI draft.

### Implementation Steps

1.  **Define the Tag**:
    Standardize a comment format (e.g., `<!-- This document is generated by @AgentName -->`).

2.  **Instruction Injection**:
    In the skill or agent definition (`.prompt.md` or `.agent.md`), explicitly instruct the model: _"You MUST include the following tag at the top of the file..."_

3.  **Adopt "Good Enough" Philosophy**:
    Encourage users (via documentation like `PROJECT_CHARTER.md` or `coding-conventions.md`) to treat tagged documents as "Junior Developer Drafts"â€”verifying key logic but accepting minor formatting or phrasing quirks.

### Example Template

````markdown
# Output Format

Generate the file with the following header:

```markdown
<!-- This document is generated and updated by .github/prompts/my-skill.prompt.md -->

# [Title]

...
```
````

### Benefits

- **Safety**: Explicit warning prompts necessary verification.
- **Efficiency**: Shifts user mindset from "Perfectionism" to "Validation," speeding up reviews.
- **Traceability**: Identifies which agent or prompt created the file.

## Stop and Ask (Circuit Breaker)

### Problem

Agents can sometimes get stuck in a loop of trying seeing errors, trying a guess fix, seeing errors again, and repeating. Or they may proceed with a fix based on a weak assumption that turns out to be wrong, wasting time and potentially damaging code.

### Solution

Explicitly instruct the agent to **STOP** and **ASK** the user if it cannot verify the root cause or if it has failed multiple times.

### Implementation Steps

1.  **Define Stop Conditions**:
    Decide on a reasonable number of attempts (e.g., 3 tries) or specific uncertainty triggers (e.g., "cannot reproduce").

2.  **Add "Constraints" or "Stop Condition" Section**:
    In the prompt or agent template, add a clear rule that overrides the "fix it" mandate.

### Example Template

```markdown
## â›” Stop Condition

If you cannot identify the root cause after **3 attempts** or if the fix requires making unverified assumptions:

1.  **STOP** execution.
2.  **Report** your findings and what you have tried so far.
3.  **Ask** the user for further guidance or more information.
```

### Benefits

- **Efficiency**: Prevents "flailing" where the agent burns tokens and time on bad paths.
- **Safety**: Reduces the chance of hallucinated "fixes" breaking things further.
- **Collaboration**: Brings the human back in the loop exactly when needed.
